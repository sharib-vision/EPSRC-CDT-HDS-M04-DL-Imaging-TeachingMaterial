{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDS-M05: Deep Learning (Exercise II)\n",
    "\n",
    "**Practical leader and prepared by:** Sharib Ali, PhD\n",
    "\n",
    "[Setup instructions](https://github.com/sharibox/tutorial/blob/master/HDS-CDT_DL.md)\n",
    "\n",
    "### Required packages\n",
    "\n",
    "[1] [matplotlib](http://matplotlib.org) can be used for plotting graphs in python\n",
    "\n",
    "[2] [pytorch](https://pytorch.org/docs/stable/index.html) is library widely used for bulding deep-learning frameworks\n",
    "\n",
    "[3] [Tensorboard](https://pytorch.org/docs/stable/tensorboard.html) is used to visualise your training and validation loss and accuracy development - It is important to observe it!!!\n",
    "\n",
    "[4] [TorchVision](https://pytorch.org/vision/stable/index.html) you can use available datasets that include one you are required to use in this tutorial (CIFAR10) and also use augmentations (meaning you can increase data variability for improved accuracy and model generalisation)\n",
    "\n",
    "[5] [Scikit-learn] Metrics\n",
    "\n",
    "**Reference:** https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/cc/Comparison_image_neural_networks.svg\" style=\"width:800px;height:200px;\">\n",
    "<caption><center> <u>Figure</u>: LeNet and AlexNet for image classification.</center></caption>\n",
    "\n",
    "    What you will learn here?\n",
    "    \n",
    "    - You will implement more complex CNN network --> AlexNet \n",
    "    - You will learn to perform validation split \n",
    "    - You will learn to plot loss and accuracy here\n",
    "    - You will use scikit learn to plot confusion matrix and other metrics direcetly as you learnt in ML03 module\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "from torch import nn\n",
    "import numpy as np\n",
    "# always check your version\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and pre-processing\n",
    "**Steps**\n",
    "\n",
    "[1] Load data - use torchvision if available in datasets ([torch vision available](https://pytorch.org/vision/stable/datasets.html))\n",
    "\n",
    "[2] Transform --> Normalise your data - mean and std (e.g., if color then normalise all three channels)\n",
    "e.g., torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "[3] Transform --> Always convert data to ToTensor (you can do **step 1, 2 and 3** in one line as done in this tutorial)\n",
    "\n",
    "[4] New: split your data into **train and validation set**\n",
    "\n",
    "[4] Make [DataLoaders](https://pytorch.org/docs/stable/data.html): It represents a Python iterable over a dataset\n",
    "\n",
    "[5] Identify labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms \n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Preparing transform for step 2 and step 3\n",
    "mean = (0.5, 0.5, 0.5)\n",
    "std = (0.5, 0.5, 0.5)\n",
    "\n",
    "# Add data augmentation --> training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),   # Note: here you will resize image to 224 that is input to the AlexNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ColorJitter(brightness=0.5),\n",
    "    transforms.ColorJitter(hue=0.25),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "testtransform = transforms.Compose([\n",
    "    transforms.Resize(224),   # Note: here you will resize image to 224 that is input to the AlexNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "# Load data and include prepared transform (Remember to apply same transform to both train \n",
    "# and test data\n",
    "trainset = CIFAR10(\"data\", download=True, train=True, transform=transform)\n",
    "\n",
    "# valset and testset needs to have same transform (remeber--> no augmentation here!)\n",
    "valset = CIFAR10(\"data\", download=True, train=True, transform=testtransform) \n",
    "testset = CIFAR10(\"data\", download=True, train=False, transform=testtransform)\n",
    "\n",
    "# labels of CIFAR10 dataset\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New: You will split train data into train and val set (say 90-10) \n",
    "- This step is crucial to identify under- and over-fitting problems \n",
    "- Later, we will visualise performance on both train and test online during training (using tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step: Split between train and valset from the overall trainset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "val_percentage = 0.1\n",
    "num_train = len(trainset)\n",
    "\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(val_percentage * num_train))\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "\n",
    "# Now create data loaders (same as before)\n",
    "# Now we need to create dataLoaders that will allow to iterate during training\n",
    "batch_size = 16 # create batch-based on how much memory you have and your data size\n",
    "\n",
    "traindataloader = DataLoader(trainset, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
    "valdataloader = DataLoader(trainset, batch_size=batch_size, sampler=valid_sampler,\n",
    "            num_workers=2,)\n",
    "\n",
    "testdataloader = DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of training samples:', len(traindataloader))\n",
    "print('Number of validation samples:', len(valdataloader))\n",
    "print('Number of testing samples:', len(testdataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look into data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to unnormalise images and using transpose to change order to [H, W, Channel] \n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# always check the shape of your training data\n",
    "dataiter = iter(traindataloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape) # batchsize , channel, Height, Width \n",
    "print(labels.shape)  # array with label in batchsize \n",
    "\n",
    "# show images \n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your AlexNet model\n",
    "- Please note that your input image size will make difference on your hard-coded feature sizes in FC-layer\n",
    "- Always be aware of what size input is used, here for convenience we will follow the original paper and reshape image to 224x224x3 \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/sharibox/HDS-CDT2020/main/images/AlexNet.png\" style=\"width:800px;height:200px;\">\n",
    "<caption><center> <u>Figure</u>: AlexNet for image classification.</center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your model \n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "#         self.features = nn.Sequential(\n",
    "            \n",
    "#         )\n",
    "# #         self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "#         self.classifier = nn.Sequential(\n",
    "\n",
    "#         )\n",
    "\n",
    "    def forward(self, x):\n",
    "   \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare an optimizer, set learning rate, and you loss function\n",
    "- Here you will use model.train and use gradients\n",
    "- Also, you will use criterion to compute loss \n",
    "- Compute metric to know how well it is performing\n",
    "- save them to display mean for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call you model \n",
    "model = AlexNet()\n",
    "lr = 0.0001\n",
    "optimiser = optim.Adam(model.parameters(), lr=lr) # weight decay (what)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare accuracy computation to know how your training is going \n",
    "\n",
    "[1] Loss function is important to keep track (mostly you minimise it, i.e. it should go down)\n",
    "\n",
    "[2] Accuracy in classification is important and you want higher accuracy\n",
    "\n",
    "[3] You can use TensorBoard to visualize both - on new terminal do below\n",
    "\n",
    "```shell\n",
    "ssh -L 8889:127.0.0.1:8889 $user@bdicdtvm01.bmrc.ox.ac.uk \n",
    "$ ml Anaconda3\n",
    "$ source activate base\n",
    "\n",
    "- run your training below and then do this while waiting:\n",
    "$ tensorboard --logdir runs/ --port 8889\n",
    "$ http://127.0.0.1:8889/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define accuracy\n",
    "def topk_accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4] Run your training loop with optimiser trying to minimise your cost/loss, dont forget to backpropagate your loss\n",
    "model.to(device)\n",
    "model.train()\n",
    "# Tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# define no. of epochs you want to loop \n",
    "epochs = 10\n",
    "log_interval = 100 # for visualising your iterations \n",
    "\n",
    "# New: savining your model depending on your best val score\n",
    "best_valid_loss = float('inf')\n",
    "ckptFileName = 'alexNet_CKPT_best.pt'\n",
    "for epoch in range(epochs):\n",
    "    train_loss, valid_loss, train_top1,val_top1  = [], [], [], []\n",
    "  \n",
    "    \n",
    "    for batch_idx, (data, label) in enumerate(traindataloader):\n",
    "        # initialise all your gradients to zero\n",
    "        optimiser.zero_grad()\n",
    "        out = model(data.to(device))\n",
    "        loss = criterion(out, label.to(device))\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        # append\n",
    "        train_loss.append(loss.item())\n",
    "        acc_1 = topk_accuracy(out, label.to(device),topk=(1,))\n",
    "        train_top1.append(acc_1[0].item())\n",
    "        \n",
    "        if (batch_idx % log_interval) == 0:\n",
    "            print('Train Epoch is: {}, train loss is: {:.6f}, train accuracy top1% is {}'.format(epoch, np.mean(train_loss),\n",
    "                                                                                           np.mean(train_top1)))\n",
    "            \n",
    "            ### --------> New -----> validation code!!! ###\n",
    "            #**New:** Compute validation loss and accuracy --> remember to use no grad (same as test) --> You can write this as function\n",
    "            # TODO: make function and call for test and val both\n",
    "            with torch.no_grad():\n",
    "                for i, (data, label) in enumerate(valdataloader):\n",
    "                    data, label = data.to(device), label.to(device)\n",
    "                    out = model(data)\n",
    "                    loss = criterion(out, label.to(device))\n",
    "                    acc_1 = topk_accuracy(out, label.to(device),topk=(1,))\n",
    "\n",
    "                    # append\n",
    "                    valid_loss.append(loss.item())\n",
    "                    acc_1 = topk_accuracy(out, label.to(device),topk=(1,))\n",
    "                    val_top1.append(acc_1[0].item())\n",
    "    \n",
    "            print('Val Epoch is: {}, val loss is: {:.6f}, val accuracy top1% is {}'.format(epoch, np.mean(valid_loss),\n",
    "                                                                                           np.mean(val_top1)))\n",
    "    \n",
    "    #New --> save your checkpoint every epoch if best\n",
    "    if np.mean(valid_loss) < best_valid_loss:\n",
    "        best_valid_loss = np.mean(valid_loss)\n",
    "        print('saving my model, improvement in validation loss achieved...')\n",
    "        torch.save(model.state_dict(), ckptFileName)\n",
    "        \n",
    "        \n",
    "    # every epoch write the loss and accuracy (these you can see plots on tensorboard)        \n",
    "    writer.add_scalar('AlexNet/train_loss', np.mean(train_loss), epoch)\n",
    "    writer.add_scalar('AlexNet/train_accuracy', np.mean(train_top1), epoch)\n",
    "    \n",
    "    # New --> add plot for your val loss and val accuracy\n",
    "    writer.add_scalar('AlexNet/val_loss', np.mean(valid_loss), epoch)\n",
    "    writer.add_scalar('AlexNet/val_accuracy', np.mean(val_top1), epoch)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test predictions in a CNN (TODO: please fill this by yourself, you can take reference from above)\n",
    "# Compute total test accuracy\n",
    "total = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in testdataloader:\n",
    "        image, labels = data\n",
    "        output = model(image.to(device))\n",
    "        _, preds_tensor = torch.max(output, 1)\n",
    "        acc_1_test = topk_accuracy(output, labels.to(device),topk=(1,) )\n",
    "        total +=np.mean(acc_1_test[0].detach().cpu().numpy())\n",
    "print('test accuracy is {}% on 10000 samples of CIFAR10 test dataset'.format(total/len(testdataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively you can compute for each class seperately as well \n",
    "#(taken from: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testdataloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images.to(device))\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label.to(device) == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New => Inference/testing on saved checkpoint\n",
    "- Load your trained model and apply test on testdataloader \n",
    "- If you have checkpoint file (trained weights) you can simply call below for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckptFileName = 'alexNet_CKPT_best.pt'\n",
    "# load the saved weights\n",
    "model.load_state_dict(torch.load(ckptFileName))\n",
    "\n",
    "# Apply testing (same as validation above)\n",
    "test_preds = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, batch in enumerate(testdataloader):\n",
    "        img, label = batch\n",
    "        img, label = img.to(device, dtype = torch.float), label.to(device, dtype = torch.long)\n",
    "        output = model(img)\n",
    "        output = output.detach().cpu().numpy()\n",
    "        test_preds.extend(np.argmax(output, 1))\n",
    "        labels.extend(label.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- New => Use scikit-learn to see the confuse matrix/compute accuracy (recall ML-03)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(labels, test_preds))\n",
    "print('Accuracy score: %f' % accuracy_score(labels, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving your network peerformance\n",
    "\n",
    "- Train for larger batch size and epochs (longer)\n",
    "- Add data augmentation provided in transforms (https://pytorch.org/vision/stable/transforms.html) -- Ask tutor if you  are confused \n",
    "- Save your training with augmentation as ``my_AlexNet_withAug.pt``\n",
    "- Tune your hyperparameters and decay rate\n",
    "- Add your tensorboard outputs for training and validation (loss and accuracy) as image files\n",
    "\n",
    "\n",
    "#### Exercise: Perform above improvements on CIFAR10 \n",
    "You can also refer to: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "- You can use this ipython notebook to do this (**Assignment to be submmitted**)\n",
    "- Due on **Wednesday 3rd November, 2021 (11:59 PM)** (*You will be graded for this exercise*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Thanks for completing this lesson!</h3>\n",
    "\n",
    "Any comments or feedbacks and your solution to exercise, please send to [Sharib Ali](sharib.ali@eng.ox.ac.uk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
