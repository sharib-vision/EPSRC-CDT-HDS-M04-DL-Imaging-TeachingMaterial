{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDS-M05: Deep Learning\n",
    "\n",
    "Module Leaders: Bartek Papiez and Sharib Ali\n",
    "\n",
    "Practical Leader and prepared by: Sharib Ali, PhD\n",
    "\n",
    "\n",
    "### Required packages\n",
    "[1] [numpy](http://www.numpy.org) is package for scientific computing with python\n",
    "\n",
    "[2] [h5py](http://www.h5py.org) is package to interact with compactly stored dataset\n",
    "\n",
    "[3] [matplotlib](http://matplotlib.org) can be used for plotting graphs in python\n",
    "\n",
    "[4] [pytorch](https://pytorch.org/docs/stable/index.html) is library widely used for bulding deep-learning frameworks\n",
    "\n",
    "### Ingrediants of DNN and CNN\n",
    "\n",
    "**What will you learn here?**\n",
    "\n",
    "Here you will build an *l-* layer neural network using pytorch. Each layer can comprise of one or more nodes. Pytorch provides a module **nn** that comprises of building blocks for networks making it easy to code.You will build both Multi-Layer Perceptron (using Fully connected layers)and Convolutional neural networks (using Fully convolutional layers).\n",
    "\n",
    "<u>For DNN concentrate on</u>:\n",
    "- Input Units\n",
    "- Hidden Units\n",
    "- Output Units\n",
    "- Activation functions\n",
    "\n",
    "<u>For CNN concentrate on</u>:\n",
    "- Convolution blocks\n",
    "- Batch normalisation\n",
    "- Maxpooling layers\n",
    "- Activation functions\n",
    "- Flattenning at the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "# always check your version\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above you have samples and labels separately while pytorch dataloader for classification takes the folders\n",
    "# We have provided you a helper function to fix this\n",
    "\n",
    "def compile_dataset_sampleLabelPair(x, y):\n",
    "    return TensorDataset(torch.from_numpy(x).float(), torch.from_numpy(y).long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design a network class for compiling your model \n",
    "##### Remember this should have all the above units\n",
    "\n",
    "nn.Linear module automatically creates a linear transformation with automatically created bias and weight tensors that is used in the forward feed. You can access these using model.hidden.weight or model.hidden.bias \n",
    "\n",
    "Recall: $z^{(i)} = w^T x^{(i)} + b \\tag{1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNetwork(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, H2,  D_out):\n",
    "        super(myNetwork, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(D_in, H)\n",
    "        self.fc2 = torch.nn.Linear(H, H2)\n",
    "        self.fc3 = torch.nn.Linear(H2, D_out)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call your model here\n",
    "#model = myNetwork(12288, 128, 128,  2)\n",
    "model = myNetwork(784, 128, 128, 10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 784*(128+1) + 128*(128+1) + 128*(10+1) = ? parameters to train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1] create your optimiser\n",
    "import torch.optim as optim\n",
    "learning_rate = 0.01 # set your learning rate (crucial)\n",
    "optimiser = optim.SGD(model.parameters(), lr = learning_rate,weight_decay=1e-6, momentum = 0.9)\n",
    "\n",
    "# 2] identify your loss function to optimise (its like a cost)\n",
    "# Note: For classification we will be using cross-entropy (if binary then use binary cross-entropy!)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3] build your data loading\n",
    "# you can use either pytorch one or a custom dataloader\n",
    "# training set\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# load MNIST data\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "# This is critical, for 3 channel images they will be different, please change here with mean and std.\n",
    "mean = (0.5)\n",
    "std = (0.5)\n",
    "_tasks = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "mnist = MNIST(\"data\", download=True, train=True, transform=_tasks)\n",
    "\n",
    "batch_size = 256\n",
    "shuffle = True # when not sampler used\n",
    "num_workers = 2\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "## create training and validation split \n",
    "split = int(0.8 * len(mnist))\n",
    "index_list = list(range(len(mnist)))\n",
    "train_idx, valid_idx = index_list[:split], index_list[split:]\n",
    "\n",
    "## create sampler objects using SubsetRandomSampler\n",
    "tr_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "## create iterator objects for train and valid datasets\n",
    "train_loader = DataLoader(mnist, batch_size=batch_size, sampler=tr_sampler, num_workers=num_workers)\n",
    "valid_loader = DataLoader(mnist, batch_size=batch_size, sampler=val_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always check the shape of your training data\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# visualizing the training images\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4] Run your training loop with optimiser trying to minimise your cost/loss, dont forget to backpropagate your loss\n",
    "device = 'cuda' # set your model to your gpu or cpu (depending on your hardware availability!)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# define no. of epochs you want to loop \n",
    "epochs = 10\n",
    "log_interval = 2\n",
    "for epoch in range(epochs):\n",
    "    train_loss, valid_loss, epoch_accuracy_top1,epoch_accuracy_top5  = [], [], [], []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #img = (data).view(-1, 64*64*3)\n",
    "        img = (data).view(-1, 28*28)\n",
    "        \n",
    "        # initialise all your gradients to zero\n",
    "        optimiser.zero_grad()\n",
    "        out = model(img.to(device))\n",
    "        loss = criterion(out, target.to(device))\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        # append\n",
    "        train_loss.append(loss.item())\n",
    "        acc_1 = topk_accuracy(out, target.to(device),topk=(1,))\n",
    "        epoch_accuracy_top1.append(acc_1[0].item())\n",
    "        \n",
    "        # TODO: perform validation here (use 20% of your test data)\n",
    "        # Your code here\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ## TODO: include validation loss and accuracy top 1% and top 5% and print\n",
    "        if (batch_idx % log_interval) == 0:\n",
    "            print('Train Epoch is: {}, train loss is: {:.6f}, train accuracy top1% is {}'.format(epoch, np.mean(train_loss),\n",
    "                                                                                               np.mean(epoch_accuracy_top1)))\n",
    "        \n",
    "            # your code here for printing validation, alternatively you can add above!\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions (This usually is separate from validation data, here we will use valid data)\n",
    "dataiter = iter(valid_loader)\n",
    "data, labels = dataiter.next()\n",
    "img = (data).view(-1, 28*28)\n",
    "output = model(img.to(device))\n",
    "\n",
    "_, preds_tensor = torch.max(output, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.squeeze(preds_tensor.detach().cpu().numpy())\n",
    "print (\"Actual:\", labels[:10])\n",
    "print (\"Predicted:\", preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train a CNN model on the same data\n",
    "\n",
    "    Here, you will be building a CNN network with convolution filters of fixed kernel sizes\n",
    "    \n",
    "    You will need to understand the shape of image and how to use kernels and max-pooling layers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        ## define the layers: you can write this all as nn.Sequence to call in one line\n",
    "        # first 2D convolution layer\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # second 2D convolution layer\n",
    "        self.conv2 = nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        # this is redundant, you can use above ones\n",
    "        self.act2 = nn.ReLU(inplace=True)\n",
    "        self.pooling2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        \n",
    "        self.fc = nn.Linear(16*7*7, 10)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.pooling(self.act(self.bn1(self.conv1(x))))\n",
    "        x = self.pooling2(self.act2(self.bn2(self.conv2(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.01 # set your learning rate (crucial)\n",
    "\n",
    "# set your optimiser (alternatively you can select other optimisers like Adam, RMSProp etc.)\n",
    "optimiser = optim.SGD(model.parameters(), lr = learning_rate,weight_decay=1e-6, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training starts here (you can make this as a function)\n",
    "model.to(device)\n",
    "for epoch in range(1, 31):\n",
    "    train_loss, valid_loss = [], []\n",
    "    model.train()\n",
    "    \n",
    "    # Todo: 1) write your training pipeline\n",
    "    # 2) write validation for your model\n",
    "    # 3) Print train and the validation loss and their top 1% accuracy\n",
    "    \n",
    "    # your code here!\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click __here__ for the partial solution.\n",
    "<!-- Your answer is below:\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimiser.zero_grad()\n",
    "        output = model(data.to(device))\n",
    "        loss = loss_function(output, target.to(device))\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        train_loss.append(loss.item()) \n",
    "        \n",
    "        if (batch_idx % log_interval) == 0:\n",
    "            print('Train Epoch is: {}, train loss is: {:.6f}'.format(epoch, np.mean(train_loss)))\n",
    "             \n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target.to(device))\n",
    "        valid_loss.append(loss.item()) \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: visualise your test input image and predicted image from your model\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation to avoid overfitting\n",
    "##### Take help from practical instructors\n",
    "\n",
    "You can follow below steps:\n",
    "\n",
    "- Convert your training section into a function\n",
    "- Build a simple augmentation and pass your data again into your dataloader\n",
    "- Call your training function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Use a different ipython notebook to classify CIFAR-10 images using AlexNet\n",
    "\n",
    "\n",
    "<img src=\"images/AlexNet.png\" style=\"width:800px;height:200px;\">\n",
    "<caption><center> <u>Figure</u>: AlexNet for image classification.</center></caption>\n",
    "\n",
    "<u> Detailed Architecture of above figure </u>:\n",
    "\n",
    "[1] CIFAR10 dataset is available in torchvision.datasets\n",
    "\n",
    "[2] 10 classes are present with image size of 32x32x3 (color RGB) \n",
    "\n",
    "[3] 60,000 image present\n",
    "\n",
    "[4] You will create an **AlexNet** architecture and train on this dataset\n",
    "More info on dataset here: <https://www.cs.toronto.edu/~kriz/cifar.html>\n",
    "\n",
    "*Hint: AlexNet was originally designed for 224x224x3 image sizes so for it to work on this data remove the last maxpool layer from the feature block and you'll end up with a 256x1x1 matrix*\n",
    "\n",
    "\n",
    "``Alternatively, you can use Breast Cancer Histology dataset <https://iciar2018-challenge.grand-challenge.org/Dataset/>. It will be made available to you.``\n",
    "\n",
    "Reference: https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
    "\n",
    "\n",
    "Due on Wednesday 4th November, 2020 (*You will be graded for this exercise*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Thanks for completing this lesson!</h3>\n",
    "\n",
    "Any comments or feedbacks, please send to [Sharib Ali](sharib.ali@eng.ox.ac.uk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
